{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Quickstart tutorial\n",
    "\n",
    "Welcome to the quickstart tutorial to Esmraldi! If you have comments or suggestions, please donâ€™t hesitate to reach out. \n",
    "This tutorial contains the key steps of the imaging processing workflow leading to the joint analysis of a MALDI image with another image. It uses a basic MALDI dataset along with a synthetic image mimicking an optical image obtained from another modality. \n",
    "\n",
    "Let's set-up our notebook to start:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys, os\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import string\n",
    "import SimpleITK as sitk\n",
    "\n",
    "rootpath = \"../../\"\n",
    "sys.path.append(os.path.join(os.path.dirname(os.path.abspath(\"__file__\")), rootpath))\n",
    "\n",
    "def display_image(image):\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(image, cmap=\"gray\")\n",
    "    plt.show()\n",
    "\n",
    "def display_images(*images):\n",
    "    fig, ax = plt.subplots(1, len(images))\n",
    "    for i in range(len(images)):\n",
    "        ax[i].axis('off')\n",
    "        ax[i].imshow(images[i], cmap=\"gray\")\n",
    "        ax[i].text(0.4, -0.2, \"(\" + string.ascii_lowercase[i] + \")\", transform=ax[i].transAxes, size=18)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Input, Visualization\n",
    "\n",
    "The data is available in the `data` directory. \n",
    "First, read the data and display the spectrum of the first pixel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import esmraldi.imzmlio as io\n",
    "\n",
    "imzml = io.open_imzml(rootpath + \"data/Example_Continuous.imzML\")\n",
    "spectra = io.get_spectra(imzml)\n",
    "\n",
    "print(spectra.shape)\n",
    "mz_first, intensities_first = spectra[0, 0], spectra[0, 1]\n",
    "plt.plot(mz_first, intensities_first)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "The variable `spectra` is a 3D numpy array, where the first dimension corresponds to pixels, the second dimension to *m/z* or intensities, and the last dimension to their associated values. Here, this array contains 9 pixels, and each spectrum has 8399 points.\n",
    "\n",
    "Then, we display the image of the ion of *m/z* 328.9 +/- 0.25:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "image = io.get_image(imzml, 328.9, 0.25)\n",
    "display_image(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Now, we read the optical image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "optical_image = plt.imread(rootpath + \"data/Example_Optical.png\")\n",
    "display_image(optical_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "The image is a 3x3 array of various intensities.\n",
    "\n",
    "## Spectra processing\n",
    "\n",
    "### Peak detection\n",
    "\n",
    "The next step is to detect peaks across all spectra. Our approach is based on [topographical prominence](https://en.wikipedia.org/wiki/Topographic_prominence) values. More specifically, we define the **local** prominence as the ratio between the prominence and the estimated local noise in the signal. The local noise $\\sigma$ is estimated as the median absolute deviations in a window of length $w$. Let $f$ be the local prominence factor, the local maxima whose intensity is above $f * \\sigma$ are considered as peaks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import esmraldi.spectraprocessing as sp\n",
    "\n",
    "prominence_local_factor = 4\n",
    "window_length = 1000\n",
    "\n",
    "detected_mzs = sp.spectra_peak_mzs_adaptative(spectra, factor=prominence_local_factor, wlen=window_length)\n",
    "detected_mz_first = detected_mzs[0]\n",
    "indices = np.in1d(mz_first, detected_mz_first)\n",
    "detected_intensities_first = intensities_first[indices]\n",
    "\n",
    "plt.plot(mz_first, intensities_first, detected_mz_first, detected_intensities_first, \"o\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "The original spectrum is displayed in blue, and the detected peaks are highlighted by orange dots.\n",
    "\n",
    "\n",
    "### Spectra alignment\n",
    "Next, the spectra need to be realigned to compensate for *m/z* differences between pixels, due to instrumentation differences, or sample inhomogeneity.\n",
    "\n",
    "Groups of close *m/z* values are made with a tolerance given by the *step* parameter. The median *m/z* value in each group is taken as reference for the alignment procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "realigned_spectra = sp.realign_mzs(spectra, detected_mzs, reference=\"median\", nb_occurrence=1, step=0.05)\n",
    "mzs = realigned_spectra[0, 0, :]\n",
    "print(realigned_spectra.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "After the realignment, 121 peaks are detected (vs. the initial 8399 peaks).\n",
    "\n",
    "## Segmentation\n",
    "\n",
    "Next, a representative image is extracted from the set of MALDI ion images. This is achieved by **region growing on a subset of relevant images**, i.e. non-noisy images.\n",
    "<\n",
    "Relevant images are found by a measure called *spatial coherence* which considers the minimum area of the largest connected component in ion binary images over a set of quantile thresholds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import esmraldi.segmentation as seg\n",
    "\n",
    "maldi_image = io.get_images_from_spectra(realigned_spectra, (3,3))\n",
    "maldi_image = io.normalize(maldi_image)\n",
    "# Relevant images\n",
    "spatially_coherent = seg.find_similar_images_area(maldi_image, 0, quantiles=[60, 70, 80, 90])\n",
    "\n",
    "# Mean image\n",
    "mean_image = np.average(spatially_coherent, axis=-1)\n",
    "\n",
    "# Region growing\n",
    "seeds = set(((1, 1), (0, 0)))\n",
    "list_end, _ = seg.region_growing(spatially_coherent, seedList=seeds, lower_threshold=50)\n",
    "x = [elem[0] for elem in list_end]\n",
    "y = [elem[1] for elem in list_end]\n",
    "mask = np.ones_like(mean_image)\n",
    "mask[x, y] = 0\n",
    "segmented_image = np.ma.array(mean_image, mask=mask)\n",
    "segmented_image = segmented_image.filled(0)\n",
    "\n",
    "display_image(segmented_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Registration\n",
    "\n",
    "At this stage, both shapes in the optical and MALDI  images can be matched. Registration methods aim at finding the transform which best aligns two objects. The transform parameters are estimated by optimizing a metric which quantifies the similarity between both images. In our case, we register **the MALDI segmented image onto the optical image**.\n",
    "\n",
    "The registration is based on the [SimpleITK](https://simpleitk.org/) library. We choose the following registration components:\n",
    "\n",
    "* **transform**: rigid transform (translation, scaling, rotation)\n",
    "* **metric**: Mattes mutual information\n",
    "* **optimizer**: regular step gradient descent\n",
    "* **interpolator**: nearest neighbor\n",
    "\n",
    "The input images must be instances of the [SimpleITK.Image](https://simpleitk.org/doxygen/latest/html/classitk_1_1simple_1_1Image.html) class.\n",
    "\n",
    "Each component takes various parameters. For the metric, the *number of bins* defines the marginal and joint histograms, the *sampling percentage* describes the proportion of pixels in the image used to compute the metric and *seed* is used to initialize the random number generator to create the sample points. Regarding the optimizer, the *learning rate* defines the initial step length, the *relaxation factor* the factor reducing the step length each time the derivative sign changes, and *min step* the stop criterion for the optimizer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import esmraldi.registration as reg\n",
    "\n",
    "segmented_itk = sitk.Cast(sitk.GetImageFromArray(segmented_image), sitk.sitkFloat32)\n",
    "optical_itk = sitk.Cast(sitk.GetImageFromArray(optical_image), sitk.sitkFloat32)\n",
    "segmented_itk = seg.resize(segmented_itk, optical_itk.GetSize())\n",
    "segmented_itk = sitk.Cast(segmented_itk, sitk.sitkFloat32)\n",
    "\n",
    "number_bins = 8\n",
    "sampling_percentage = 0.1\n",
    "registration = reg.register(optical_itk, segmented_itk, number_bins, sampling_percentage, seed=0, learning_rate=0.8, relaxation_factor=0.8, min_step=0.0001)\n",
    "registered_seg_itk = registration.Execute(segmented_itk)\n",
    "registered_seg_image = sitk.GetArrayFromImage(registered_seg_itk)\n",
    "\n",
    "display_images(optical_image, segmented_image, registered_seg_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "(a&#8291;) Optical fixed image, (b) original MALDI segmented image and (c) registered MALDI image.\n",
    "\n",
    "Finally, we apply the registration to the original MALDI image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "registered_itk = sitk.GetImageFromArray(maldi_image)\n",
    "registered_itk = seg.resize(registered_itk, optical_itk.GetSize())\n",
    "registered_itk = sitk.Cast(registered_itk, sitk.sitkFloat32)\n",
    "size = registered_itk.GetSize()\n",
    "size = [size[2], size[1], size[0]]\n",
    "out_register = sitk.Image(size, registered_itk.GetPixelID() )\n",
    "\n",
    "for i in range(registered_itk.GetSize()[0]):\n",
    "    slice = registered_itk[i, :, :]\n",
    "    slice.SetSpacing(optical_itk.GetSpacing())\n",
    "    slice_registered = registration.Execute(slice)\n",
    "    slice_registered = sitk.JoinSeries(slice_registered)\n",
    "    out_register = sitk.Paste(out_register, slice_registered, slice_registered.GetSize(), destinationIndex=[0, 0, i])\n",
    "\n",
    "registered_image = np.transpose(sitk.GetArrayFromImage(out_register), (1, 2, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Joint statistical analysis\n",
    "\n",
    "The final step of the workflow is to find the MALDI ion images whose distribution correlate with the optical image.\n",
    "\n",
    "We choose non-negative matrix factorization (NMF) to find spatial correlations. \n",
    "First, the registered MALDI image is factorized, then, the MRI image is projected into the reduced space, and correlations are established based on the distance in this space.\n",
    "\n",
    "We search for the 3 ion images which are closest to the optical image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import esmraldi.fusion as fusion\n",
    "\n",
    "optical_flatten = fusion.flatten(optical_image)\n",
    "maldi_flatten = fusion.flatten(registered_image)\n",
    "\n",
    "# Reduction by NMF\n",
    "fit_red = fusion.nmf(maldi_flatten, n=7)\n",
    "reduction = fit_red.transform(maldi_flatten)\n",
    "point_optical = fit_red.transform(optical_flatten)\n",
    "weights = [1 for i in range(reduction.shape[1])]\n",
    "\n",
    "similar_images, similar_mzs, distances = fusion.select_images(registered_image, point_optical, reduction, weights, mzs, labels=None, top=None)\n",
    "\n",
    "print(\"Closest m/z ratio \", similar_mzs[:3])\n",
    "display_images(optical_image, similar_images[..., 0], similar_images[..., 1], similar_images[..., 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "(a&#8291;) Optical image, (b-d) MALDI ion images which are closest to the optical image: *m/z*= (b) 129.0 , (c) 143.17, (d) 143.25."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "argv": [
    "python",
    "-m",
    "ipykernel_launcher",
    "-f",
    "{connection_file}"
   ],
   "display_name": "Python 3",
   "env": null,
   "interrupt_mode": "signal",
   "language": "python",
   "metadata": null,
   "name": "python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "name": "quickstart.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
