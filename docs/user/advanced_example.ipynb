{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Advanced example\n",
    "\n",
    "This guide shows how to analyze real images jointly. It is recommended to start off with the [Quickstart Tutorial](quickstart.ipynb) before engaging in this example. The dataset consists of a MALDI and optical images of mouse urinary bladder. These are processed images from original images downloaded from PRIDE (dataset id [PXD001283](https://www.ebi.ac.uk/pride/archive/projects/PXD001283)).\n",
    "\n",
    "The images are located in the ``data/Mouse_Urinary_Bladder_PXD001283/`` directory: ms_image_resized.imzML, optical_image.tiff.\n",
    "\n",
    "We aim at finding the spatial correlations between the ion images in MALDI and the optical image.\n",
    "\n",
    "\n",
    "## Data processing\n",
    "\n",
    "The following section explains how the images were processed from the original images available from PRIDE. It is **not necessary to replicate these steps**, but they are detailed for reproducibility purposes. Jump straight to [Fusion workflow](#Fusion-workflow) if you wish to get started with this example.\n",
    "\n",
    "The original MALDI image from PRIDE has different *m-z* values. First, all spectra are aligned on the same *m/z*-axis following the procedure described in the [Data](data.rst) section (parameters: *factor*=150, *level*=2, *nbpeaks*=1, *step*=0.02). Then, the images are resized using the ``examples/resize_imzml.py`` script with a 0.5 scale factor.\n",
    "\n",
    "Peak selection and alignment are already done, thus there is **no need for further spectra processing**.\n",
    "\n",
    "In essence, the following scripts were applied. First, we download the data from PRIDE:\n",
    "\n",
    "```bash\n",
    "cd data/Mouse_Urinary_Bladder_PXD001283/\n",
    "python download.py\n",
    "```\n",
    "\n",
    "After completion (might take a while), the three following downloaded files should be located in the ``data/Mouse_Urinary_Bladder_PXD001283``: ms_image.imzML, ms_image.imzML, and optical_image.tiff.\n",
    "\n",
    "Next, we align and resize the image:\n",
    "\n",
    "```bash\n",
    "cd ../../\n",
    "python -m examples.same_mz_axis -i data/Mouse_Urinary_Bladder_PXD001283/ms_image.imzML -o data/Mouse_Urinary_Bladder_PXD001283/ms_image_aligned.imzML -f 150 -l 2 -n 1 -s 0.02\n",
    "python -m examples.resize_imzml -i data/Mouse_Urinary_Bladder_PXD001283/ms_image_aligned.imzML -o data/Mouse_Urinary_Bladder_PXD001283/ms_image_resized.imzML -f 0.5\n",
    "```\n",
    "\n",
    "The optical image is transformed by a 5Â° counter-clockwise rotation followed by a +100 px translation on the *x*-axis and a scaling by a factor of 0.9.\n",
    "\n",
    "\n",
    "## Fusion workflow\n",
    "\n",
    "Let's import the necessary modules and define some utility functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys, os\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import string\n",
    "import SimpleITK as sitk\n",
    "\n",
    "rootpath = \"../../\"\n",
    "imagepath = \"data/Mouse_Urinary_Bladder_PXD001283/\"\n",
    "sys.path.append(os.path.join(os.path.dirname(os.path.abspath(\"__file__\")), rootpath))\n",
    "\n",
    "def display_image(image):\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(image, cmap=\"gray\")\n",
    "    plt.show()\n",
    "\n",
    "def display_images(*images):\n",
    "    fig, ax = plt.subplots(1, len(images))\n",
    "    for i in range(len(images)):\n",
    "        ax[i].axis('off')\n",
    "        ax[i].imshow(images[i], cmap=\"gray\")\n",
    "        ax[i].text(0.4, -0.2, \"(\" + string.ascii_lowercase[i] + \")\", transform=ax[i].transAxes, size=18)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Input, Visualization\n",
    "\n",
    "The data is available in the `data/Mouse_Urinary_Bladder_PXD001283` directory.\n",
    "First, read the data and display the spectrum of a pixel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import esmraldi.imzmlio as io\n",
    "\n",
    "imzml = io.open_imzml(rootpath + imagepath + \"ms_image_resized.imzML\")\n",
    "spectra = io.get_spectra(imzml)\n",
    "\n",
    "print(spectra.shape)\n",
    "mz_first, intensities_first = spectra[1, 0], spectra[1, 1]\n",
    "indices = intensities_first > 1\n",
    "plt.stem(mz_first[indices], intensities_first[indices], use_line_collection=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "The variable `spectra` is a 3D numpy array, with 8711 pixels (67x130) and where each pixel is associated to a spectrum with 214 peaks. The peaks are already selected and aligned for this dataset.\n",
    "\n",
    "Then, we display the image of the ion of *m/z* 741.7 +/- 0.25:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "image = io.get_image(imzml, 741.7, 0.25)\n",
    "display_image(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Now, we read the optical image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from skimage import io as skio\n",
    "\n",
    "optical_image = skio.imread(rootpath + imagepath + \"optical_image.png\", as_gray=True)\n",
    "display_image(optical_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Segmentation\n",
    "\n",
    "Next, a representative image is extracted from the set of MALDI ion images. This is achieved by **region growing on a subset of relevant images**, i.e. non-noisy images."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "raw_mimetype": "text/restructuredtext",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Relevant images are found by the :func:`spatial coherence <esmraldi.segmentation.spatial_coherence>`  measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import esmraldi.segmentation as seg\n",
    "\n",
    "maldi_image = io.to_image_array(imzml)\n",
    "maldi_image = np.transpose(maldi_image, (1, 0, 2))\n",
    "maldi_image = io.normalize(maldi_image)\n",
    "\n",
    "# Relevant images\n",
    "spatially_coherent = seg.find_similar_images_spatial_coherence(maldi_image, 300, quantiles=[60, 70, 80, 90])\n",
    "\n",
    "# Mean image\n",
    "mean_image = np.average(spatially_coherent, axis=-1)\n",
    "\n",
    "# Region growing\n",
    "seeds = set(((1, 1), (0, 0)))\n",
    "list_end, _ = seg.region_growing(spatially_coherent, seedList=seeds, lower_threshold=30)\n",
    "x = [elem[0] for elem in list_end]\n",
    "y = [elem[1] for elem in list_end]\n",
    "mask = np.ones_like(mean_image)\n",
    "mask[x, y] = 0\n",
    "segmented_image = np.ma.array(mean_image, mask=mask)\n",
    "segmented_image = segmented_image.filled(0)\n",
    "\n",
    "display_image(segmented_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Registration\n",
    "\n",
    "At this stage, both shapes in the optical and MALDI  images can be matched. In our case, we register **the MALDI segmented image onto the optical image**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import esmraldi.registration as reg\n",
    "import esmraldi.imageutils as utils\n",
    "\n",
    "segmented_itk = sitk.Cast(sitk.GetImageFromArray(segmented_image), sitk.sitkFloat32)\n",
    "optical_itk = sitk.Cast(sitk.GetImageFromArray(optical_image), sitk.sitkFloat32)\n",
    "segmented_itk = utils.resize(segmented_itk, optical_itk.GetSize())\n",
    "segmented_itk = sitk.Cast(segmented_itk, sitk.sitkFloat32)\n",
    "\n",
    "number_bins = 8\n",
    "sampling_percentage = 0.1\n",
    "registration = reg.register(optical_itk, segmented_itk, number_bins, sampling_percentage, seed=0, learning_rate=0.8, relaxation_factor=0.8, min_step=0.0001)\n",
    "registered_seg_itk = registration.Execute(segmented_itk)\n",
    "registered_seg_image = sitk.GetArrayFromImage(registered_seg_itk)\n",
    "\n",
    "display_images(optical_image, segmented_image, registered_seg_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "(a&#8291;) Optical fixed image, (b) original MALDI segmented image and (c) registered MALDI image.\n",
    "\n",
    "Finally, we apply the registration to the original MALDI image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "registered_itk = sitk.GetImageFromArray(maldi_image)\n",
    "registered_itk = utils.resize(registered_itk, optical_itk.GetSize())\n",
    "registered_itk = sitk.Cast(registered_itk, sitk.sitkFloat32)\n",
    "size = registered_itk.GetSize()\n",
    "\n",
    "size = [size[1], size[2], size[0]]\n",
    "out_register = sitk.Image(size, registered_itk.GetPixelID() )\n",
    "\n",
    "for i in range(registered_itk.GetSize()[0]):\n",
    "    slice = registered_itk[i, :, :]\n",
    "    slice.SetSpacing(optical_itk.GetSpacing())\n",
    "    slice_registered = registration.Execute(slice)\n",
    "    slice_registered = sitk.JoinSeries(slice_registered)\n",
    "    out_register = sitk.Paste(out_register, slice_registered, slice_registered.GetSize(), destinationIndex=[0, 0, i])\n",
    "\n",
    "registered_image = np.transpose(sitk.GetArrayFromImage(out_register), (1, 2, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Joint statistical analysis\n",
    "\n",
    "The final step of the workflow is to find the MALDI ion images whose distribution correlate with the optical image.\n",
    "\n",
    "We use non-negative matrix factorization (NMF) to find spatial correlations.\n",
    "\n",
    "We search for the 3 ion images which are closest to the optical image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import esmraldi.fusion as fusion\n",
    "\n",
    "optical_flatten = fusion.flatten(optical_image)\n",
    "maldi_flatten = fusion.flatten(registered_image, is_spectral=True)\n",
    "\n",
    "# Reduction by NMF\n",
    "mzs = spectra[0, 0, :]\n",
    "fit_red = fusion.nmf(maldi_flatten, n=5)\n",
    "reduction = fit_red.transform(maldi_flatten)\n",
    "point_optical = fit_red.transform(optical_flatten)\n",
    "weights = [1 for i in range(reduction.shape[1])]\n",
    "\n",
    "similar_images, similar_mzs, distances = fusion.select_images(registered_image, point_optical, reduction, weights, mzs, labels=None, top=None)\n",
    "\n",
    "print(\"Closest m/z ratio \", similar_mzs[:3])\n",
    "display_images(optical_image, similar_images[..., 0], similar_images[..., 1], similar_images[..., 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "argv": [
    "python",
    "-m",
    "ipykernel_launcher",
    "-f",
    "{connection_file}"
   ],
   "display_name": "Python 3 (ipykernel)",
   "env": null,
   "interrupt_mode": "signal",
   "language": "python",
   "metadata": {
    "debugger": true
   },
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "name": "advanced_example.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
